{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01245902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "#Every Nuron has a unique connection to every single previous nuron. Every unique input is also going to have a unique weight associate with it\n",
    "#Creates a basic neuron with 3 inputs.\n",
    "inputs = [1,2,3,2.5]\n",
    "weights= [0.2, 0.8 , -0.5, 1.0]\n",
    "bias= 2\n",
    "output =inputs[0] * weights[0] + inputs[1] * weights[1] + inputs[2] * weights[2] + inputs[3] * weights[3] + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e774bbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.9\n"
     ]
    }
   ],
   "source": [
    "#Every Nuron has a unique connection to every single previous nuron. Every unique input is also going to have a unique weight associate with it \n",
    "input = [1,2,3,2.5]\n",
    "weights = [3.1,2.1,8.7,9.0]\n",
    "bias = 3\n",
    "output =input[0] * weights[0] + input[1] * weights[1] + input[2] * weights[2]  + input[3] * weights[3] + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f635c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80.7, 65.24, 8.659999999999997]\n"
     ]
    }
   ],
   "source": [
    "#Every Nuron has a unique connection to every single previous nuron. Every unique input is also going to have a unique weight associate with it \n",
    "#Creates a simple layer of neurons, with 4 inputs.\n",
    "input = [1.2,5.1,2.1,5]\n",
    "weights1 = [3.1,2.1,8.7,9.0]\n",
    "weights2 = [2.1,4.1,6.1,5.0]\n",
    "weights3 = [1.7,3.5,-6.3,-0.6]\n",
    "bias1 = 3\n",
    "bias2 = 4\n",
    "bias3 =5\n",
    "output = [input[0] * weights1[0] + input[1] * weights1[1] + input[2] * weights1[2]  + input[3] * weights1[3] + bias1,\n",
    "          input[0] * weights2[0] + input[1] * weights2[1] + input[2] * weights2[2]  + input[3] * weights2[3] + bias2,\n",
    "          input[0] * weights3[0] + input[1] * weights3[1] + input[2] * weights3[2]  + input[3] * weights3[3] + bias3 \n",
    "         ]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1db5407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "#Example 3 The Dot Product\n",
    "import numpy as np\n",
    "inputs = [1,2,3,2.5]\n",
    "weights= [0.2, 0.8 , -0.5, 1.0]\n",
    "bias= 2\n",
    "output = np.dot(weights , inputs) + bias\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fb25671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "#Example 4 Batches, Layers, and Objects\n",
    "#Doing dot product with a layer of neurons and multiple inputs\n",
    "import numpy as np\n",
    "inputs = [1,2,3,2.5]\n",
    "weights= [[0.2, 0.8 , -0.5, 1.0],\n",
    "          [0.5,-0.91,0.26,-0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3 , 0.5]\n",
    "output = np.dot(weights , inputs) + biases\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc7b9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "#Example 5 Batches, Layers, and Objects\n",
    "import numpy as np\n",
    "inputs = [[1,2,3,2.5],\n",
    "          [2.0,5.0,-1.0,2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights= [[0.2, 0.8, -0.5, 1.0],\n",
    "          [0.5,-0.91,0.26,-0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3 , 0.5]\n",
    "output = np.dot(inputs , np.array(weights).T) + biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f396e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17640523  0.04001572  0.0978738 ]\n",
      " [ 0.22408932  0.1867558  -0.09772779]\n",
      " [ 0.09500884 -0.01513572 -0.01032189]\n",
      " [ 0.04105985  0.01440436  0.14542735]]\n",
      "[[ 0.24760702  0.23532634  0.92183326 -0.87480338  0.38839981]\n",
      " [-0.07425198  0.5616412  -0.27137893 -1.03333399  0.69668176]\n",
      " [ 0.13069026 -0.30125977  0.33428499 -1.23169487 -0.06278753]]\n",
      "[[ 0.0764005   0.03676484]\n",
      " [-0.07936267 -0.07683314]\n",
      " [ 0.09429592  0.05574692]]\n"
     ]
    }
   ],
   "source": [
    "#Example 6 Batches, Layers, and Objects\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "X =[[1,2,3,2.5],\n",
    "    [2.0,5.0,-1.0,2.0],\n",
    "    [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs , n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "print(0.10*np.random.randn(4,3))\n",
    "\n",
    "layer1 = Layer_Dense(4,5)\n",
    "layer2 = Layer_Dense(5,2)\n",
    "layer1.forward(X)\n",
    "print(layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200fc8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65504505e-04\n",
      "  4.56846210e-05]\n",
      " [0.00000000e+00 5.93469958e-05 0.00000000e+00 2.03573116e-04\n",
      "  6.10024377e-04]\n",
      " ...\n",
      " [1.13291524e-01 0.00000000e+00 0.00000000e+00 8.11079666e-02\n",
      "  0.00000000e+00]\n",
      " [1.34588361e-01 0.00000000e+00 3.09493970e-02 5.66337556e-02\n",
      "  0.00000000e+00]\n",
      " [1.07817926e-01 0.00000000e+00 0.00000000e+00 8.72561932e-02\n",
      "  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Example 7\n",
    "#Relu activation\n",
    "import numpy as np \n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data  # See for code: https://gist.github.com/Sentdex/454cb20ec5acf0e76ee8ab8448e6266c\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "X, y = spiral_data(100, 3)   \n",
    "\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "\n",
    "layer1 = Layer_Dense(2,5)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "layer1.forward(X)\n",
    "\n",
    "#print(layer1.output)\n",
    "activation1.forward(layer1.output)\n",
    "print(activation1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f99244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\tf-new\\lib\\site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7da5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nnfs\n",
      "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\tf-new\\lib\\site-packages (from nnfs) (1.21.5)\n",
      "Installing collected packages: nnfs\n",
      "Successfully installed nnfs-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc8de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33331734 0.3333183  0.33336434]\n",
      " [0.3332888  0.33329153 0.33341965]\n",
      " [0.33325943 0.33326396 0.33347666]\n",
      " [0.33323312 0.33323926 0.33352762]]\n"
     ]
    }
   ],
   "source": [
    "#Softmax activation\n",
    "import numpy as np \n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2,3)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b83027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n",
      "0.35667494393873245\n",
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "#Calculating the loss with Categorical Cross Entropy\n",
    "import math\n",
    "\n",
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "target_output = [1, 0, 0]\n",
    "\n",
    "loss = -(math.log(softmax_output[0]) * target_output[0] +\n",
    "         math.log(softmax_output[1]) * target_output[1] +\n",
    "         math.log(softmax_output[2]) * target_output[2])\n",
    "\n",
    "print(loss)\n",
    "\n",
    "print(-math.log(0.7))\n",
    "print(-math.log(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef390200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.3333332  0.3333332  0.33333364]\n",
      " [0.3333329  0.33333293 0.3333342 ]\n",
      " [0.3333326  0.33333263 0.33333477]\n",
      " [0.33333233 0.3333324  0.33333528]]\n",
      "Loss: 1.0986104\n"
     ]
    }
   ],
   "source": [
    "#Applying Categorical Cross Entropy loss to our NNFS framework\n",
    "import numpy as np \n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2,3)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n",
    "\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd4c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
